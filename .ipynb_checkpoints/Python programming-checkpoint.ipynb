{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables that contain user credentials to access Twitter API\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener #allow us to listen firehose of tweets\n",
    "from tweepy import OAuthHandler #Authentication of credentials\n",
    "from tweepy import Stream \n",
    "\n",
    "from tweepy import API\n",
    "from tweepy import Cursor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To extract timeline tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient():\n",
    "    def __init__(self, twitter_user=None):\n",
    "        self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
    "        self.twitter_client = API(self.auth)\n",
    "\n",
    "        self.twitter_user = twitter_user\n",
    "        \n",
    "    def get_twitter_client_api(self):\n",
    "        return self.twitter_client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication by key credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterAuthenticator():\n",
    "    \n",
    "    def authenticate_twitter_app(self):\n",
    "        auth = OAuthHandler(consumer_key, consumer_secret) #auth object\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        return auth\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for Streaming and processing live Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterStreamer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.twitter_authenticator = TwitterAuthenticator()\n",
    "    \n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles twitter authentication and the connection to the twitter Streaming API\n",
    "        \n",
    "        \n",
    "    \n",
    "        listener = TwitterListener(fetched_tweets_filename) #Listener Object\n",
    "        auth = self.twitter_authenticator.authenticate_twitter_app()\n",
    "        stream = Stream(auth, listener)\n",
    "        \n",
    "        stream.filter(track=hash_tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with data and errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a basic listener class that just prints recieved tweets to stdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to print streamed data and showing error of any.\n",
    "\n",
    "class TwitterListener(StreamListener):\n",
    "    \n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "    \n",
    "    def on_data(self, data): #use the data genetated from StreamListener\n",
    "        try:\n",
    "            print(data)\n",
    "            with open(self.fetched_tweets_filename,'a') as tf:\n",
    "                tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error_on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status): #to print status message of error on screen\n",
    "        if status == 420:\n",
    "            return False\n",
    "        print(status)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality for analyzing and categorizing content from tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the no of photos we use the extended_entites object whose json format is given in https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/extended-entities-object.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetAnalyzer():\n",
    "    \n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "        \n",
    "    \n",
    "    \n",
    "        df['date'] = np.array([tweet.created_at for tweet in tweets])               #to get the date and time of tweet\n",
    "        df['likes']=np.array([tweet.favorite_count for tweet in tweets])            #to get the number of like son tweet\n",
    "        df['retweet_count'] = np.array([tweet.retweet_count for tweet in tweets])   #to count no. of retweets\n",
    "                \n",
    "        count = 0\n",
    "        i = 1\n",
    "        photo = []\n",
    "        for tweet in tweets:\n",
    "            K=[]\n",
    "            count = 0\n",
    "            if 'media' in tweet.entities:\n",
    "                K = list(k for k,v in tweet.extended_entities.items() if 'media' in k.lower())\n",
    "                if(K!=[]):\n",
    "                    for T in tweet.extended_entities['media']:\n",
    "                        if(T['type']=='photo'):\n",
    "                            count+=1                          #Counting the no. of photos in a tweet\n",
    "\n",
    "            i+=1\n",
    "            if(count!=0):\n",
    "                photo.append(count)\n",
    "            else:\n",
    "                photo.append(\"None\")                        #when there will be no photo in the tweet\n",
    "        df[\"photo\"]=photo\n",
    "        return df\n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of objects, main part of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #hash_tag_list = [\"MIDAS\"]\n",
    "    \n",
    "    #fetched_tweets_filename = \"tweets.txt\"\n",
    "    \n",
    "    #twitter_client = TwitterClient('midasIIITD')\n",
    "    #print(twitter_client.get_user_timeline_tweets(1))\n",
    "    \n",
    "    #twitter_streamer = TwitterStreamer()\n",
    "    #witter_streamer.stream_tweets(fetched_tweets_filename, hash_tag_list)\n",
    "    \n",
    "    twitter_client = TwitterClient()\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "    api = twitter_client.get_twitter_client_api()\n",
    "    '''The twitter handle from which tweets to be extracted and no. of tweets. In this case the maximum tweets taht can be fetched\n",
    "    are 200'''\n",
    "    \n",
    "    tweets = api.user_timeline(screen_name=\"\", count=200) #Screen name will be username of which want to fetch tweets\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get the media urls present in the tweet when there is media present in tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    if 'media' in tweet.entities:\n",
    "        for media in tweet.extended_entities['media']:\n",
    "            print (media['media_url'])\n",
    "            if (media['media_url']) and (media[\"type\"]==\"photo\"):\n",
    "                print(media['media_url'])\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing the tweets having media enitity in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "i = 1\n",
    "photo = []\n",
    "for tweet in tweets:\n",
    "    K=[]\n",
    "    K = list(k for k,v in tweet.entities.items() if 'media' in k.lower())\n",
    "    if(K!=[]):\n",
    "        print(i,\": \",tweet.entities['media'])\n",
    "        count+=1        \n",
    "        if 'media' in tweet.entities:\n",
    "            for media in tweet.extended_entities['media']:\n",
    "                print (media['media_url'])\n",
    "        photo.append(1)\n",
    "    i+=1\n",
    "print(\"Media Count: \",count)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To print the media url of media as photos type, it won't count the media files of pinned tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "i = 1\n",
    "photo = []\n",
    "for tweet in tweets:\n",
    "    K=[]\n",
    "    count = 0\n",
    "    if 'media' in tweet.entities:\n",
    "        K = list(k for k,v in tweet.extended_entities.items() if 'media' in k.lower())\n",
    "        if(K!=[]):\n",
    "            for T in tweet.extended_entities['media']:\n",
    "                if(T['type']=='photo'):\n",
    "                    print(i,\": \",(T['media_url']))\n",
    "                    count+=1\n",
    "        \n",
    "    i+=1\n",
    "    if(count!=0):\n",
    "        photo.append(count)\n",
    "    else:\n",
    "        photo.append(None)\n",
    "photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing the tweets in dataframe by categorizing the tweet contents in different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exporting of dataframes to json fromat in index format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = df.to_json(r'output.json',orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
